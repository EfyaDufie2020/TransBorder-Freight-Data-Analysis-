# Transborder Freight Analysis: A Comprehensive Analysis of Trade Data

The project aims to leverage data analysis to extract actionable insights that address key business objectives. By implementing the CRISP-DM (Cross-Industry Standard Process for Data Mining) framework, this analysis will systematically explore the dataset provided and deliver value through insightful visualizations and actionable recommendations.


# Transborder Freight Analysis: A Comprehensive Analysis of Trade Data

## Table of Contents
1. Introduction
2. Data Collection and Preparation
3. Exploratory Data Analysis (EDA)
4. Feature Engineering
5. Data Cleaning and Imputation
6. Analysis and Visualization
7. Conclusion

## 1. Introduction

The Transborder Freight Analysis is a comprehensive analysis of trade data collected from various sources, including the United States Customs and Border Protection (CBP) and the Mexican Secretariat of Commerce (SECOFI). The dataset includes information on the value, weight, and type of goods transported between the United States and Mexico.

The goal of this analysis is to provide insights into the trade patterns, trends, and factors influencing the movement of goods across the border. By analyzing the data, we can identify patterns, correlations, and potential areas for improvement in trade efficiency and security.

## 2. Data Collection and Preparation

The data was collected from various sources, including the CBP and SECOFI websites. The data was then cleaned and prepared for analysis. The following steps were taken to prepare the data:

1. Data extraction: Raw data was extracted from the CBP and SECOFI websites.
2. Data cleaning: The extracted data was cleaned to remove any inconsistencies, errors, or missing values.
3. Data merging: The cleaned data from both sources was merged to create a single dataset.
4. Data transformation: The merged dataset was transformed to include additional features and mappings for better analysis.

## 3. Exploratory Data Analysis (EDA)

Exploratory Data Analysis (EDA) was performed on the prepared dataset to gain insights into the data. The following steps were taken during EDA:

1. Summary statistics: Summary statistics were calculated to understand the central tendency, dispersion, and distribution of the data.
2. Data visualization: Data was visualized using various plots and charts to identify patterns, trends, and outliers.
3. Feature correlation analysis: Correlation analysis was performed to identify relationships between different features in the dataset.

## 4. Feature Engineering

Feature engineering was performed to create new features that would be useful for analysis. The following features were created:

1. US State: The U.S. state code was mapped to its corresponding state name.
2. Mexican State: The Mexican state code was mapped to its corresponding state name.
3. Trade Type: The trade type code was mapped to its corresponding trade type (export or import).
4. Disaggregation Method: The disaggregation method code was mapped to its corresponding disaggregation method.
5. Country: The country code was mapped to its corresponding country name.

## 5. Data Cleaning and Imputation

Data cleaning and imputation were performed to handle missing values and inconsistencies in the dataset. The following steps were taken:

1. Missing value handling: Missing values were identified and handled using appropriate techniques such as imputation with the mean, median, or mode.
2. Inconsistency handling: Inconsistencies were identified and corrected, if necessary.

## 6. Analysis and Visualization

The cleaned and prepared dataset was then analyzed and visualized to identify patterns, trends, and insights. The following analysis and visualization techniques were used:

1. Descriptive statistics: Descriptive statistics were calculated to summarize the data and identify key characteristics.
2. Data visualization: Data was visualized using various plots and charts to identify patterns, trends, and outliers.
3. Correlation analysis: Correlation analysis was performed to identify relationships between different features in the dataset.
4. Time series analysis: Time series analysis was performed to identify trends and patterns over time.

## 7. Conclusion

The Transborder Freight Analysis provided valuable insights into the trade patterns, trends, and factors influencing the movement of goods across the border. By analyzing the data, we were able to identify patterns, correlations, and potential areas for improvement in trade efficiency and security.

Further analysis and visualization can be performed to gain deeper insights into the data and to inform decision-making processes related to trade policy, security, and efficiency.

## Acknowledgments

I would like to thank the Azubi Technical Team providing the data used in this analysis. Their efforts insharing this valuable information have made this project possible.

## Contact Information

For any questions or inquiries, please contact:

Name: [Mercy Dufie Boateng ]
Email: [mercydboateng@ymail.com]
